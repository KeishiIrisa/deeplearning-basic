{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03FTy4lwzXiQ"
      },
      "source": [
        "# 第2回講義 宿題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtnWqKVGzXiT"
      },
      "source": [
        "## 課題\n",
        "今回のLessonで学んだことを元に，MNISTのファッション版 (Fashion MNIST，クラス数10) をソフトマックス回帰によって分類してみましょう．\n",
        "\n",
        "Fashion MNISTの詳細については以下のリンクを参考にしてください．\n",
        "\n",
        "Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyD3F677zXiU"
      },
      "source": [
        "### 目標値\n",
        "Accuracy: 80%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pt9rMcxzXiU"
      },
      "source": [
        "### ルール\n",
        "- 訓練データは`x_train`， `y_train`，テストデータは`x_test`で与えられます．\n",
        "- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください．\n",
        "- **下のセルで指定されている`x_train、y_train`以外の学習データは使わないでください．**\n",
        "- **ソフトマックス回帰のアルゴリズム部分の実装はnumpyのみで行ってください** (sklearnやtensorflowなどは使用しないでください)．\n",
        "    - データの前処理部分でsklearnの関数を使う (例えば `sklearn.model_selection.train_test_split`) のは問題ありません．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bq41q5SzXiV"
      },
      "source": [
        "### 提出方法\n",
        "- 2つのファイルを提出していただきます．\n",
        "    1. テストデータ (`x_test`) に対する予測ラベルを`submission_pred.csv`として保存し，**Omnicampusの宿題タブから「第2回 機械学習基礎」を選択して**提出してください．\n",
        "    2. それに対応するpythonのコードを`submission_code.py`として保存し，**Omnicampusの宿題タブから「第2回 機械学習基礎 (code)」を選択して**提出してください．pythonファイル自体の提出ではなく，「提出内容」の部分にコードをコピー&ペーストしてください．\n",
        "      \n",
        "- なお，採点は1で行い，2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）．コードの内容を変更した場合は，**1と2の両方を提出し直してください**．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJKR8DMtzXiW"
      },
      "source": [
        "### 評価方法\n",
        "- 予測ラベルの`y_test`に対する精度 (Accuracy) で評価します．\n",
        "- 即時採点しLeader Boardを更新します（採点スケジュールは別アナウンス）．\n",
        "- 締切時の点数を最終的な評価とします．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVM6MjD_4Okx"
      },
      "source": [
        "### ドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oI-Fjs4btCn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r20uRSCUzXiX"
      },
      "source": [
        "### データの読み込み（このセルは修正しないでください）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZodouZWzXiX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sys.modules['tensorflow'] = None\n",
        "\n",
        "def load_fashionmnist():\n",
        "    # 学習データ\n",
        "    x_train = np.load('drive/MyDrive/Colab Notebooks/DLBasics2025_colab/Lecture02/data/x_train.npy')\n",
        "    y_train = np.load('drive/MyDrive/Colab Notebooks/DLBasics2025_colab/Lecture02/data/y_train.npy')\n",
        "\n",
        "    # テストデータ\n",
        "    x_test = np.load('drive/MyDrive/Colab Notebooks/DLBasics2025_colab/Lecture02/data/x_test.npy')\n",
        "\n",
        "    x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
        "    y_train = np.eye(10)[y_train.astype('int32')]\n",
        "    x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
        "\n",
        "    return x_train, y_train, x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sys.modules['tensorflow'] = None\n",
        "\n",
        "def load_fashionmnist():\n",
        "    # 学習データ\n",
        "    x_train = np.load('x_train.npy')\n",
        "    y_train = np.load('y_train.npy')\n",
        "\n",
        "    # テストデータ\n",
        "    x_test = np.load('x_test.npy')\n",
        "\n",
        "    x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
        "    y_train = np.eye(10)[y_train.astype('int32')]\n",
        "    x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
        "\n",
        "    return x_train, y_train, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHynK8xAzXid"
      },
      "source": [
        "### ソフトマックス回帰の実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gU9E1ppuzXie"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1, Valid Cost: 2.908, Valid Accuracy: 0.343\n",
            "Learning rate reduced to 0.80000\n",
            "EPOCH: 10, Valid Cost: 6.476, Valid Accuracy: 0.376\n",
            "Learning rate reduced to 0.64000\n",
            "EPOCH: 20, Valid Cost: 2.825, Valid Accuracy: 0.637\n",
            "Learning rate reduced to 0.51200\n",
            "EPOCH: 30, Valid Cost: 1.088, Valid Accuracy: 0.724\n",
            "Learning rate reduced to 0.40960\n",
            "Learning rate reduced to 0.32768\n",
            "EPOCH: 40, Valid Cost: 0.857, Valid Accuracy: 0.770\n",
            "EPOCH: 50, Valid Cost: 0.859, Valid Accuracy: 0.769\n",
            "EPOCH: 60, Valid Cost: 0.836, Valid Accuracy: 0.772\n",
            "EPOCH: 70, Valid Cost: 0.823, Valid Accuracy: 0.777\n",
            "EPOCH: 80, Valid Cost: 0.808, Valid Accuracy: 0.780\n",
            "EPOCH: 90, Valid Cost: 0.802, Valid Accuracy: 0.783\n",
            "EPOCH: 100, Valid Cost: 0.777, Valid Accuracy: 0.785\n",
            "EPOCH: 110, Valid Cost: 0.817, Valid Accuracy: 0.786\n",
            "EPOCH: 120, Valid Cost: 0.712, Valid Accuracy: 0.792\n",
            "Learning rate reduced to 0.26214\n",
            "Learning rate reduced to 0.20972\n",
            "EPOCH: 130, Valid Cost: 0.598, Valid Accuracy: 0.811\n",
            "EPOCH: 140, Valid Cost: 0.545, Valid Accuracy: 0.825\n",
            "EPOCH: 150, Valid Cost: 0.538, Valid Accuracy: 0.828\n",
            "EPOCH: 160, Valid Cost: 0.534, Valid Accuracy: 0.828\n",
            "Learning rate reduced to 0.16777\n",
            "EPOCH: 170, Valid Cost: 0.534, Valid Accuracy: 0.825\n",
            "EPOCH: 180, Valid Cost: 0.522, Valid Accuracy: 0.829\n",
            "EPOCH: 190, Valid Cost: 0.519, Valid Accuracy: 0.830\n",
            "EPOCH: 200, Valid Cost: 0.517, Valid Accuracy: 0.830\n",
            "EPOCH: 210, Valid Cost: 0.515, Valid Accuracy: 0.831\n",
            "EPOCH: 220, Valid Cost: 0.512, Valid Accuracy: 0.831\n",
            "EPOCH: 230, Valid Cost: 0.510, Valid Accuracy: 0.832\n",
            "EPOCH: 240, Valid Cost: 0.508, Valid Accuracy: 0.833\n",
            "EPOCH: 250, Valid Cost: 0.506, Valid Accuracy: 0.834\n",
            "EPOCH: 260, Valid Cost: 0.505, Valid Accuracy: 0.834\n",
            "EPOCH: 270, Valid Cost: 0.503, Valid Accuracy: 0.834\n",
            "EPOCH: 280, Valid Cost: 0.501, Valid Accuracy: 0.835\n",
            "EPOCH: 290, Valid Cost: 0.500, Valid Accuracy: 0.834\n",
            "EPOCH: 300, Valid Cost: 0.498, Valid Accuracy: 0.835\n",
            "EPOCH: 310, Valid Cost: 0.497, Valid Accuracy: 0.835\n",
            "EPOCH: 320, Valid Cost: 0.496, Valid Accuracy: 0.836\n",
            "EPOCH: 330, Valid Cost: 0.494, Valid Accuracy: 0.837\n",
            "EPOCH: 340, Valid Cost: 0.493, Valid Accuracy: 0.837\n",
            "EPOCH: 350, Valid Cost: 0.492, Valid Accuracy: 0.837\n",
            "EPOCH: 360, Valid Cost: 0.491, Valid Accuracy: 0.838\n",
            "EPOCH: 370, Valid Cost: 0.489, Valid Accuracy: 0.838\n",
            "EPOCH: 380, Valid Cost: 0.488, Valid Accuracy: 0.838\n",
            "EPOCH: 390, Valid Cost: 0.487, Valid Accuracy: 0.839\n",
            "EPOCH: 400, Valid Cost: 0.486, Valid Accuracy: 0.839\n",
            "EPOCH: 410, Valid Cost: 0.485, Valid Accuracy: 0.839\n",
            "EPOCH: 420, Valid Cost: 0.484, Valid Accuracy: 0.840\n",
            "EPOCH: 430, Valid Cost: 0.483, Valid Accuracy: 0.841\n",
            "EPOCH: 440, Valid Cost: 0.482, Valid Accuracy: 0.841\n",
            "EPOCH: 450, Valid Cost: 0.482, Valid Accuracy: 0.842\n",
            "EPOCH: 460, Valid Cost: 0.481, Valid Accuracy: 0.842\n",
            "EPOCH: 470, Valid Cost: 0.480, Valid Accuracy: 0.843\n",
            "EPOCH: 480, Valid Cost: 0.479, Valid Accuracy: 0.843\n",
            "EPOCH: 490, Valid Cost: 0.478, Valid Accuracy: 0.843\n",
            "EPOCH: 500, Valid Cost: 0.478, Valid Accuracy: 0.843\n",
            "EPOCH: 510, Valid Cost: 0.477, Valid Accuracy: 0.844\n",
            "EPOCH: 520, Valid Cost: 0.476, Valid Accuracy: 0.844\n",
            "EPOCH: 530, Valid Cost: 0.475, Valid Accuracy: 0.844\n",
            "EPOCH: 540, Valid Cost: 0.475, Valid Accuracy: 0.844\n",
            "EPOCH: 550, Valid Cost: 0.474, Valid Accuracy: 0.844\n",
            "EPOCH: 560, Valid Cost: 0.473, Valid Accuracy: 0.844\n",
            "EPOCH: 570, Valid Cost: 0.473, Valid Accuracy: 0.844\n",
            "EPOCH: 580, Valid Cost: 0.472, Valid Accuracy: 0.844\n",
            "EPOCH: 590, Valid Cost: 0.471, Valid Accuracy: 0.844\n",
            "EPOCH: 600, Valid Cost: 0.471, Valid Accuracy: 0.845\n",
            "EPOCH: 610, Valid Cost: 0.470, Valid Accuracy: 0.844\n",
            "EPOCH: 620, Valid Cost: 0.469, Valid Accuracy: 0.844\n",
            "EPOCH: 630, Valid Cost: 0.469, Valid Accuracy: 0.844\n",
            "EPOCH: 640, Valid Cost: 0.468, Valid Accuracy: 0.844\n",
            "EPOCH: 650, Valid Cost: 0.468, Valid Accuracy: 0.845\n",
            "EPOCH: 660, Valid Cost: 0.467, Valid Accuracy: 0.845\n",
            "EPOCH: 670, Valid Cost: 0.467, Valid Accuracy: 0.845\n",
            "EPOCH: 680, Valid Cost: 0.466, Valid Accuracy: 0.845\n",
            "EPOCH: 690, Valid Cost: 0.466, Valid Accuracy: 0.846\n",
            "EPOCH: 700, Valid Cost: 0.465, Valid Accuracy: 0.846\n",
            "EPOCH: 710, Valid Cost: 0.465, Valid Accuracy: 0.846\n",
            "EPOCH: 720, Valid Cost: 0.464, Valid Accuracy: 0.847\n",
            "EPOCH: 730, Valid Cost: 0.464, Valid Accuracy: 0.847\n",
            "EPOCH: 740, Valid Cost: 0.463, Valid Accuracy: 0.847\n",
            "EPOCH: 750, Valid Cost: 0.463, Valid Accuracy: 0.847\n",
            "EPOCH: 760, Valid Cost: 0.462, Valid Accuracy: 0.847\n",
            "EPOCH: 770, Valid Cost: 0.462, Valid Accuracy: 0.847\n",
            "EPOCH: 780, Valid Cost: 0.461, Valid Accuracy: 0.847\n",
            "EPOCH: 790, Valid Cost: 0.461, Valid Accuracy: 0.848\n",
            "EPOCH: 800, Valid Cost: 0.461, Valid Accuracy: 0.847\n",
            "EPOCH: 810, Valid Cost: 0.460, Valid Accuracy: 0.847\n",
            "EPOCH: 820, Valid Cost: 0.460, Valid Accuracy: 0.847\n",
            "EPOCH: 830, Valid Cost: 0.459, Valid Accuracy: 0.847\n",
            "EPOCH: 840, Valid Cost: 0.459, Valid Accuracy: 0.848\n",
            "EPOCH: 850, Valid Cost: 0.459, Valid Accuracy: 0.848\n",
            "EPOCH: 860, Valid Cost: 0.458, Valid Accuracy: 0.848\n",
            "EPOCH: 870, Valid Cost: 0.458, Valid Accuracy: 0.848\n",
            "EPOCH: 880, Valid Cost: 0.457, Valid Accuracy: 0.848\n",
            "EPOCH: 890, Valid Cost: 0.457, Valid Accuracy: 0.849\n",
            "EPOCH: 900, Valid Cost: 0.457, Valid Accuracy: 0.849\n",
            "EPOCH: 910, Valid Cost: 0.456, Valid Accuracy: 0.849\n",
            "EPOCH: 920, Valid Cost: 0.456, Valid Accuracy: 0.849\n",
            "EPOCH: 930, Valid Cost: 0.456, Valid Accuracy: 0.850\n",
            "EPOCH: 940, Valid Cost: 0.455, Valid Accuracy: 0.850\n",
            "EPOCH: 950, Valid Cost: 0.455, Valid Accuracy: 0.850\n",
            "EPOCH: 960, Valid Cost: 0.455, Valid Accuracy: 0.850\n",
            "EPOCH: 970, Valid Cost: 0.454, Valid Accuracy: 0.850\n",
            "EPOCH: 980, Valid Cost: 0.454, Valid Accuracy: 0.850\n",
            "EPOCH: 990, Valid Cost: 0.454, Valid Accuracy: 0.850\n",
            "EPOCH: 1000, Valid Cost: 0.453, Valid Accuracy: 0.851\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train, x_test = load_fashionmnist()\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def np_log(x):\n",
        "    return np.log(np.clip(a=x, a_min=1e-10, a_max=1e+10))\n",
        "\n",
        "def softmax(x):\n",
        "    x -= x.max(axis=1, keepdims=True)\n",
        "    x_exp = np.exp(x)\n",
        "    return x_exp / x_exp.sum(axis=1, keepdims=True)\n",
        "\n",
        "# 重み\n",
        "W = np.random.uniform(low=-0.08, high=0.08, size=(784, 10)).astype('float32')\n",
        "b = np.zeros(shape=(10,)).astype('float32')\n",
        "\n",
        "# 学習データと検証データに分割\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1)\n",
        "\n",
        "def train(x, y, eps=1.0):\n",
        "    global W, b\n",
        "\n",
        "    batch_size = x.shape[0]\n",
        "\n",
        "    y_hat = softmax(np.matmul(x, W) + b)\n",
        "    cost = (-y * np_log(y_hat)).sum(axis=1).mean()\n",
        "    delta = y_hat - y\n",
        "\n",
        "    dW = np.matmul(x.T, delta) / batch_size\n",
        "    db = np.matmul(np.ones(shape=(batch_size,)), delta)  / batch_size\n",
        "    W -= eps * dW\n",
        "    b -= eps * db\n",
        "    return cost\n",
        "\n",
        "def valid(x, y):\n",
        "    y_hat = softmax(np.matmul(x, W) + b)\n",
        "    cost = (-y * np_log(y_hat)).sum(axis=1).mean()\n",
        "    return cost, y_hat\n",
        "\n",
        "initial_eps = 1.0\n",
        "eps = initial_eps\n",
        "\n",
        "best_valid_cost = float('inf')\n",
        "patience = 0\n",
        "patience_threshold = 5\n",
        "improvement_threshold = 1e-4\n",
        "eps_reduction_factor = 0.8\n",
        "eps_minimum_threshold = 0.15\n",
        "\n",
        "for epoch in range(1000):\n",
        "    cost = train(x_train, y_train, eps=eps)\n",
        "\n",
        "    cost, y_pred = valid(x_valid, y_valid)\n",
        "\n",
        "    if best_valid_cost - cost > improvement_threshold:\n",
        "        best_valid_cost = cost\n",
        "        patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "    \n",
        "    if patience > patience_threshold and eps*eps_reduction_factor > eps_minimum_threshold:\n",
        "        eps *= eps_reduction_factor\n",
        "        patience = 0\n",
        "        print('Learning rate reduced to {:.5f}'.format(eps))\n",
        "\n",
        "    if epoch % 10 == 9 or epoch == 0:\n",
        "        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "            epoch + 1,\n",
        "            cost,\n",
        "            accuracy_score(y_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "        ))\n",
        "\n",
        "y_pred = softmax(np.matmul(x_test, W) + b)\n",
        "\n",
        "submission = pd.Series(y_pred.argmax(axis=1), name='label')\n",
        "submission.to_csv('submission_pred.csv', header=True, index_label='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning-basic-of8fkVpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
